{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Behavioral Cloning** \n",
    "\n",
    "---\n",
    "\n",
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals / steps of this project:\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/modelarchitecture.png \"Model Visualization\"\n",
    "[image2]: ./examples/center-image.jpg \"Center Camera\"\n",
    "[image3]: ./examples/roi.png \"Croping and Normalization\"\n",
    "[image4]: ./examples/firstconv.png \"First Convolutional Layer\"\n",
    "[image5]: ./examples/secondconv.png \"Second Convolutional Layer\"\n",
    "\n",
    "---\n",
    "### Files Structure:\n",
    "\n",
    "#### 1. Files structure:\n",
    "\n",
    "The project includes:\n",
    "* model.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* writeup_report.md or writeup_report.pdf summarizing the results\n",
    "\n",
    "#### 2. Run the code\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing \n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n",
    "---\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Model architecture design\n",
    "\n",
    "At first glance, the problem is to find the steering angle and the speed of the car with input from image(s) that capture from three cameras mounted on board. This is a regression problem. To create feature map from input image(s), several convolutional layer can be used. The model should also includes multiple dense layers to handle nonlinearity.\n",
    "Due to the constrain of the data format that the simulatior sends and receives, all input preprocessing steps has to be included inside the model.\n",
    "\n",
    "#### 2. Reduce overfitting\n",
    "\n",
    "To reduce overfitting, driving-clockwise data also was collected eventhough during the autonomous mode, the simulator only drive counter clock-wise direction.\n",
    "\n",
    "#### 3. Model parameter tuning\n",
    "\n",
    "The model used an adam optimizer, so the learning rate was not tuned manually.\n",
    "\n",
    "#### 4. Appropriate training data\n",
    "Training data was chosen to keep the vehicle driving in the middle the road. Also, recovering from left and right of the road was also collected by placing the car off the center and start recording while driving back to the center.\n",
    "Trainning data from center camera is sufficient enough for the car to perform well on the test track, so no further data augmentation was performed.\n",
    "\n",
    "---\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "\n",
    "My first step was to use a neuron net with serveral dense layers. However, the result was not very good and the car seem too sensitive to the changing of input images.\n",
    "\n",
    "Few convolutional layers was used to filter out noise and to create feature maps for the model. Croping and normalization also was used to help the model train faster and perform better.\n",
    "\n",
    "\n",
    "#### 2. Final Model Architecture\n",
    "\n",
    "The final model that is used in this project was deverloped by NVIDIA autonomous driving team. More information cound be found  [here](https://devblogs.nvidia.com/deep-learning-self-driving-cars/)\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "Here is a sumarry of the architecture:\n",
    "\n",
    "```python\n",
    "from keras.models import load_model\n",
    "model = load_model(\"model.h5\")\n",
    "print (model.summary())\n",
    "```\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    lambda_2 (Lambda)            (None, 160, 320, 3)       0         \n",
    "    _________________________________________________________________\n",
    "    cropping2d_2 (Cropping2D)    (None, 65, 320, 3)        0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_6 (Conv2D)            (None, 31, 158, 24)       1824      \n",
    "    _________________________________________________________________\n",
    "    conv2d_7 (Conv2D)            (None, 14, 77, 36)        21636     \n",
    "    _________________________________________________________________\n",
    "    conv2d_8 (Conv2D)            (None, 5, 37, 48)         43248     \n",
    "    _________________________________________________________________\n",
    "    conv2d_9 (Conv2D)            (None, 3, 35, 64)         27712     \n",
    "    _________________________________________________________________\n",
    "    conv2d_10 (Conv2D)           (None, 1, 33, 64)         36928     \n",
    "    _________________________________________________________________\n",
    "    flatten_2 (Flatten)          (None, 2112)              0         \n",
    "    _________________________________________________________________\n",
    "    dense_5 (Dense)              (None, 100)               211300    \n",
    "    _________________________________________________________________\n",
    "    dense_6 (Dense)              (None, 50)                5050      \n",
    "    _________________________________________________________________\n",
    "    dense_7 (Dense)              (None, 10)                510       \n",
    "    _________________________________________________________________\n",
    "    dense_8 (Dense)              (None, 1)                 11        \n",
    "    =================================================================\n",
    "    Total params: 348,219\n",
    "    Trainable params: 348,219\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________\n",
    "    None\n",
    "\n",
    "\n",
    "#### 3. Creation of the Training Data & Training Process\n",
    "\n",
    "To capture good driving behavior, serveral laps around the track was recorded. Here is anexample of image captured by center camera:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "Data generator was created due to a tremendous amount of data was collected and could not be stored onto memory:\n",
    "```python\n",
    "# Define genorator for training\n",
    "from random import shuffle\n",
    "def generator(data, batch_size = 128):\n",
    "    data_size = len(data)\n",
    "    # Loop for ever in generator loop\n",
    "    while 1:\n",
    "        shuffle(data)\n",
    "        for offset in range(0, data_size, batch_size):\n",
    "            batch = data[offset:offset+batch_size]\n",
    "            images = []\n",
    "            mesurements = []\n",
    "            for x in batch:\n",
    "                # This is a work around because train data was collected on both Windows and Linux\n",
    "                # Hence path file contain different deliminator ('/' and '\\')\n",
    "                center_image_file = x[0].split('center_')[-1]\n",
    "                img = Image.open(\"../training-data/IMG/center_\"+center_image_file)\n",
    "                images.append(np.array(img))\n",
    "                img.close()\n",
    "                mesurements.append(float(x[3]))\n",
    "                \n",
    "            # Convert into np array\n",
    "            x_train = np.array(images)\n",
    "            y_train = np.array(mesurements)\n",
    "            \n",
    "            yield x_train, y_train\n",
    "```\n",
    "\n",
    "After data preparation, model was trained and saved into .h5 file:\n",
    "\n",
    "```python\n",
    "# Compile model\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "# Train model on train data\n",
    "model.fit_generator(train_generator, steps_per_epoch=ceil(len(train_data)/batch_size), validation_data=validation_generator,validation_steps=ceil(len(valid_data)/batch_size), shuffle=True, epochs=100, verbose=1)\n",
    "\n",
    "# Save whole model into .h5 file\n",
    "model.save(\"model.h5\")\n",
    "```\n",
    "#### 4. Model visualization of internal model:\n",
    "To see how model learn from training data, we plot feature maps that were created by inner layers of model:\n",
    "\n",
    "Croping and normalization:\n",
    "![alt text][image3]\n",
    "\n",
    "First convolutional layer:\n",
    "![alt text][image4]\n",
    "\n",
    "Second convolutional layer:\n",
    "![alt text][image5]\n",
    "\n",
    "We can see that model picks up the lane marks and the detail of the side of the road and learn how to react to these information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
